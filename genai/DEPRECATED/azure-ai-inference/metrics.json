{
    "schemaVersion": "1.0",
    "metrics": [
      {
        "id": "count_chat_calls_azureaiinference",
        "displayName": "Number of chat calls",
        "description": "The number of chat calls. The default desired direction is increase: appropriate for those looking to increase usage of chat features. However, this choice of direction is inappropriate if primary concern is cost, in which case the metric definition should be updated to specify `Decrease` as the desiredDirection.",
        "lifecycle": "Active",
        "tags": [
          "__azureaiinference__",
          "Usage",
          "Important"
        ],
        "desiredDirection": "Increase",
        "definition": {
          "kind": "EventCount",
          "event": {
            "eventName": "azureaiinference.chat"
          }
        }
      },
      {
        "id": "count_chat_users_azureaiinference",
        "displayName": "Number of chat users",
        "description": "The number of users with at least one chat call. The default desired direction is increase: appropriate for those looking to increase usage of chat features.",
        "lifecycle": "Active",
        "tags": [
          "__azureaiinference__",
          "Usage"
        ],
        "desiredDirection": "Increase",
        "definition": {
          "kind": "UserCount",
          "event": {
            "eventName": "azureaiinference.chat"
          }
        }
      },
      {
        "id": "avg_chat_tokens_azureaiinference",
        "displayName": "Average chat usage tokens",
        "description": "The average usage tokens (both input and output) per OpenAI chat call. Note that a single request may spark multiple OpenAI chat calls -- as when tool calls are initiated as part of the request. Each chat call contributes 1 vote to this metric. Assuming equal # of chat calls, we want total token usage to reduce or remain constant. Note: this is a normalization of the total token usage metric and so will have matching statistical significance.",
        "lifecycle": "Active",
        "tags": [
          "__azureaiinference__",
          "Cost",
          "Important"
        ],
        "desiredDirection": "Decrease",
        "definition": {
          "kind": "Average",
          "value": {
            "eventName": "azureaiinference.chat",
            "eventProperty": "['oe.tokens']"
          }
        }
      },
      {
        "id": "sum_chat_tokens_azureaiinference",
        "displayName": "Total chat usage tokens",
        "description": "The total usage tokens (both input and output) for OpenAI chat calls. Assuming equal number of chat calls, we want total token usage to reduce or remain constant. The statistical test on this metric compares the token usage per event: meaning increased usage may increase the total usage tokens without flagging this metric as statistically significant.",
        "lifecycle": "Active",
        "tags": [
          "__azureaiinference__",
          "Cost",
          "Important"
        ],
        "desiredDirection": "Decrease",
        "definition": {
          "kind": "Sum",
          "value": {
            "eventName": "azureaiinference.chat",
            "eventProperty": "['oe.tokens']"
          }
        }
      },
      {
        "id": "avg_chat_call_duration_azureaiinference",
        "displayName": "Average chat call duration [ms] ",
        "description": "The average duration in milliseconds per OpenAI chat operation. Duration is measured by the DurationMS property of the span capturing chat call completion.",
        "lifecycle": "Active",
        "tags": [
          "__azureaiinference__",
          "Performance",
          "Important"
        ],
        "desiredDirection": "Decrease",
        "definition": {
          "kind": "Average",
          "value": {
            "eventName": "azureaiinference.chat",
            "eventProperty": "DurationMS",
            "filter": "DurationMS > 0"
          }
        }
      }
    ]
  }